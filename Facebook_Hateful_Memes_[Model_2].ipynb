{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facebook_Hateful_Memes [Model 2].ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1El9LF8NZeo-XdrAzQSBiVCGM1ZrE696R",
      "authorship_tag": "ABX9TyMqICQ4Cs0ZeXS3lDcUibkk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashaditya369/mutlimodal-models/blob/main/Facebook_Hateful_Memes_%5BModel_2%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjGA4i9q5WVa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "# device = 'cpu'\n",
        "print(\"Using device : \", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7A-61zZ6HWE"
      },
      "source": [
        "train_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/train.jsonl\",lines = True)\n",
        "dev_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/dev.jsonl\",lines = True)\n",
        "test_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/test.jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-FIv75d9WPK"
      },
      "source": [
        "print(\"Train Size:\",train_data.shape[0])\n",
        "print(\"Test Size:\",test_data.shape[0])\n",
        "print(\"Dev Size:\",dev_data.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgfdM_QYa-o2"
      },
      "source": [
        "def progress_batch(i,Len, width=30):\n",
        "  left = int(width * (i+1)*100/Len) // 100\n",
        "  right = width - left\n",
        "  print('\\r[', '*' * left, ' ' * right, ']',f'{str(i+1)}/{str(Len)}', sep='', end='', flush=True)\n",
        "def progress(percent=0, width=30):\n",
        "  left = int(width * percent) // 100\n",
        "  right = width - left\n",
        "  print('\\r[', '#' * left, ' ' * right, ']',f' {percent:.2f}%',sep='', end='', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0bGrmbo-hS"
      },
      "source": [
        "#Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTa45CKDHJg7"
      },
      "source": [
        "##Working With Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKePH6n4qOTP"
      },
      "source": [
        "import re\n",
        "def change_begari_things(sentences):\n",
        "  chunk_words = {\n",
        "      \"i'm\": \"i am\",\n",
        "      \"don't\": \"do not\",\n",
        "      \"you're\": \"you are\",\n",
        "      \"it's\": \"it is\",\n",
        "      \"can't\": \"can not\",\n",
        "      \"that's\": \"that is\",\n",
        "      \"doesn't\": \"does not\",\n",
        "      \"i'll\": \"i will\",\n",
        "      \"didn't\": \"did not\",\n",
        "      \"he's\":\"he is\",\n",
        "      \"what's\": \"what is\",\n",
        "      \"there's\": \"there is\",\n",
        "      \"isn't\": \"is not\",\n",
        "      \"she's\": \"she is\",\n",
        "      \"let's\": \"let us\",\n",
        "      \"i've\": \"i have\",\n",
        "      \"they're\": \"they are\",\n",
        "      \"we're\": \"we are\",\n",
        "      \"ain't\": \"am not\",\n",
        "      \"you've\": \"you have\",\n",
        "      \"aren't\": \"are not\",\n",
        "      \"you'll\": \"you will\",\n",
        "      \"here's\": \"here is\",\n",
        "      \"haven't\": \"have not\",\n",
        "      \"i'd\": \"i had\",\n",
        "      \"they'll\": \"they will\",\n",
        "      \"won't\": \"will not\",\n",
        "      \"who's\": \"who is\",\n",
        "      \"where's\": \"where is\",\n",
        "      \"couldn't\": \"could not\",\n",
        "      \"shouldn't\": \"should not\",\n",
        "      \"wasn't\": \"was not\",\n",
        "      \"we'll\": \"we will\",\n",
        "      \"idk\": \"i do not know\",\n",
        "      \"y'all\": \"you all\",\n",
        "      \"wife's\": \"wife is\",\n",
        "      \"hasn't\": \"has not\",\n",
        "      \"she'll\": \"she will\",\n",
        "      \"we've\": \"we have\",\n",
        "      \"they've\":\"they have\",\n",
        "      \"wouldn't\": \"would not\",\n",
        "      \"name's\": \"name is\",\n",
        "      \"why's\": \"why is\",\n",
        "      \"that'd\": \"that would\",\n",
        "      \"lyin'\": \"lying\",\n",
        "      \"weren't\": \"were not\"\n",
        "  }\n",
        "  final_sentences = []\n",
        "  for sentence in sentences:\n",
        "    for key in chunk_words.keys():\n",
        "      if key in sentence:\n",
        "        sentence = sentence.replace(key,chunk_words[key])\n",
        "    sentence = re.sub(r\"'[a-z] \", ' ', sentence)\n",
        "    sentence = re.sub(r\"'\", ' ', sentence)\n",
        "    final_sentences.append(sentence)\n",
        "  return final_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zrJSFCwHIhR"
      },
      "source": [
        "glove_path = \"/content/drive/My Drive/Facebook Hateful Memes\"\n",
        "vectors = []\n",
        "words = []\n",
        "word2idx = {}\n",
        "idx = 0\n",
        "EMBED_DIM = 100\n",
        "Glove_PATH = glove_path+\"/glove.6B.\"+str(EMBED_DIM)+\"d.txt\"\n",
        "with open(Glove_PATH, 'rb') as f:\n",
        "    for l in f:\n",
        "        line = l.decode().split()\n",
        "        word = line[0]\n",
        "        words.append(word)\n",
        "        word2idx[word] = idx\n",
        "        idx += 1\n",
        "        vect = np.array(line[1:]).astype(np.float)\n",
        "        vectors.append(vect)\n",
        "glove = {w: vectors[word2idx[w]] for w in words}\n",
        "print(\"GLove Loaded from\",Glove_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkHRdvA_ZmX6"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "texts = train_data['text']\n",
        "sentences = change_begari_things(list(texts))\n",
        "tokenizer  = Tokenizer(oov_token='unk')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "VOCAB_SIZE = len(word_index)\n",
        "print(\"Vocab Size: \",len(word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KDdn47UatIs"
      },
      "source": [
        "def get_embedding(glove,word_index):\n",
        "  matrix_len = len(word_index)+1\n",
        "  vocab = list(word_index)\n",
        "  emb_dim = EMBED_DIM\n",
        "  weights_matrix = np.zeros((matrix_len,EMBED_DIM))\n",
        "  words_found = 0\n",
        "  words_not_found = []\n",
        "  for word in vocab:\n",
        "    try:\n",
        "      weights_matrix[word_index[word]] = glove[word]\n",
        "      words_found+=1\n",
        "    except:\n",
        "      words_not_found.append(word)\n",
        "      weights_matrix[word_index[word]] = np.random.normal(scale = 0.6,size = (emb_dim,))\n",
        "  weights_matrix_tensor = torch.FloatTensor(weights_matrix).to(device)\n",
        "  embedding = nn.Embedding.from_pretrained(weights_matrix_tensor).to(device)\n",
        "  return embedding,matrix_len,emb_dim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UQAx3gZeDzg"
      },
      "source": [
        "embedding,vocab_size,emb_dim = get_embedding(glove,word_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNPUZ5-dkcf6"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences,maxlen = 32)\n",
        "text_tensor = to_tensor(padded).squeeze(0).long().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pquwWl8aofvr"
      },
      "source": [
        "def get_text_tensor(data, tokenizer = tokenizer):\n",
        "  texts = data['text']\n",
        "  sentences = change_begari_things(list(texts))\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "  padded = pad_sequences(sequences,maxlen = 32)\n",
        "  text_tensor = to_tensor(padded).squeeze(0).long()\n",
        "  return text_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DExKyByNsq3N"
      },
      "source": [
        "#Image Feature Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qif4cpuMv7Wa"
      },
      "source": [
        "def get_image_tensor(PATH,for_conv = False):\n",
        "  image_feature = np.load(PATH,allow_pickle=True)\n",
        "  final_image_tensor = torch.empty(image_feature.shape[0],512,49)\n",
        "  if for_conv:\n",
        "    final_image_tensor = torch.empty(image_feature.shape[0],512,7,7)\n",
        "  for i,image in enumerate(image_feature):\n",
        "    if not for_conv:\n",
        "      image = image.reshape(image.shape[0]*image.shape[1],image.shape[2])\n",
        "      image = image.T\n",
        "    image_tensor = to_tensor(image)\n",
        "    final_image_tensor[i]= image_tensor\n",
        "  return final_image_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGJGk6u2XCA"
      },
      "source": [
        "class TextImageLabels(Dataset):\n",
        "  def __init__(self,text_tensor,image_tensor,label_tensor):\n",
        "    self.text = text_tensor\n",
        "    self.image = image_tensor\n",
        "    self.labels = label_tensor\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "  def __getitem__(self, idx):\n",
        "    return (self.text[idx],self.image[idx],self.labels[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d19oMq-e37dJ"
      },
      "source": [
        "def get_dataset(PATH,data,tokenizer = tokenizer,for_conv = False):\n",
        "  text_tensor = get_text_tensor(data,tokenizer)\n",
        "  print(\"Text Tensor:\",type(text_tensor),text_tensor.shape)\n",
        "  image_tensor = get_image_tensor(PATH,for_conv)\n",
        "  print(\"Image Tensor:\",type(image_tensor),image_tensor.shape)\n",
        "  label_tensor = torch.Tensor(data['label']).view(image_tensor.size(0),1)\n",
        "  print(\"Label Tensor:\", type(label_tensor),label_tensor.shape)\n",
        "  dataset = TextImageLabels(text_tensor,image_tensor,label_tensor)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LFyAF4BY_op"
      },
      "source": [
        "PATH_train = \"/content/drive/My Drive/Facebook Hateful Memes/train_channel_features.npy\"\n",
        "train_dataset = get_dataset(PATH_train,train_data,tokenizer,for_conv = True)\n",
        "PATH_dev = \"/content/drive/My Drive/Facebook Hateful Memes/dev_channel_features.npy\"\n",
        "dev_dataset = get_dataset(PATH_dev,dev_data,tokenizer,for_conv = True)\n",
        "PATH_test = \"/content/drive/My Drive/Facebook Hateful Memes/test_channel_features.npy\"\n",
        "# dev_dataset = get_dataset(PATH_test,test_data,tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Zd0fnp0qrx"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIrIM4IKGJ0A"
      },
      "source": [
        "VOCAB_SIZE = len(word_index)+1\n",
        "HIDDEN_SIZE = 64\n",
        "print(VOCAB_SIZE,HIDDEN_SIZE,EMBED_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOdkjbkZyzjL"
      },
      "source": [
        "class imageModel(nn.Module):\n",
        "  def __init__(self,out_channel = 50):\n",
        "    super(imageModel,self).__init__()\n",
        "    self.conv1 = nn.Conv2d(512,out_channel,kernel_size=3,padding=1)\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = x.view(x.size(0),x.size(1),-1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2JYguNV6gsZ"
      },
      "source": [
        "class textModel(nn.Module):\n",
        "  def __init__(self,mlp_size = 64, d_x = 128,dropout = 0.3):\n",
        "    super(textModel,self).__init__()\n",
        "    self.mlp_size = mlp_size\n",
        "    self.d_x = d_x\n",
        "    self.embed,self.vocab_size,self.embed_dim = get_embedding(glove,word_index)\n",
        "    self.mlp = nn.Linear(self.embed_dim,self.mlp_size)\n",
        "    self.dropout = nn.Dropout(p = 0.4)\n",
        "    # self.LSTM = nn.LSTM(self.mlp_size,self.d_x,batch_first = True)\n",
        "  def forward(self,x,hidden = None):\n",
        "    embedded = self.embed(x)\n",
        "    output = self.mlp(embedded)\n",
        "    output = torch.tanh(output)\n",
        "    output = self.dropout(output)\n",
        "    # output,_ = self.LSTM(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UshabwhOD6hS"
      },
      "source": [
        "class GatedDotProduct(nn.Module):\n",
        "  def __init__(self,d, d_g = 128):\n",
        "    super(GatedDotProduct,self).__init__()\n",
        "    self.d = d\n",
        "    self.d_g = d_g\n",
        "    # self.fcq = nn.Linear(d,d_g)\n",
        "    # self.fck = nn.Linear(d,d_g)\n",
        "    self.fcg = nn.Linear(d,2)\n",
        "  def forward(self,K,Q):\n",
        "    # k_output = self.fck(K)\n",
        "    # q_output = self.fcq(Q)\n",
        "    kmulq = Q*K\n",
        "    M = torch.sigmoid(self.fcg(kmulq))\n",
        "    M_q = M[:,:,0].unsqueeze(2)\n",
        "    M_k = M[:,:,1].unsqueeze(2)\n",
        "    d_tensor = torch.Tensor([self.d]).to(device)\n",
        "    A = F.softmax(torch.matmul(Q*M_q,torch.transpose(K*M_k, 1, 2))/torch.sqrt(d_tensor),-1)\n",
        "    return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YXU7vtsJRWx"
      },
      "source": [
        "class GSA(nn.Module):\n",
        "  def __init__(self,d,d_g=128):\n",
        "    super(GSA,self).__init__()\n",
        "    self.fcv = nn.Linear(d,d)\n",
        "    self.fck = nn.Linear(d,d)\n",
        "    self.fcq = nn.Linear(d,d)\n",
        "    self.gdp = GatedDotProduct(d,d_g)\n",
        "  def forward(self,z):\n",
        "    v_output = self.fcv(z)\n",
        "    k_output = self.fck(z)\n",
        "    q_output = self.fcq(z)\n",
        "    gdp_output = self.gdp(k_output,q_output)\n",
        "    F = torch.matmul(gdp_output,v_output)\n",
        "    return F\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reDle3M7Lrl7"
      },
      "source": [
        "class UA(torch.nn.Module):\n",
        "  def __init__(self,d,d_g,num_features):\n",
        "    super(UA, self).__init__()\n",
        "    self.gsaunit = GSA(d,d_g)\n",
        "    self.batchnorm1 = nn.BatchNorm1d(num_features)\n",
        "    # self.ffn1 = nn.Linear(d,4*d)\n",
        "    # self.ffn2 = nn.Linear(4*d,d)\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    # self.batchnorm2 = nn.BatchNorm1d(num_features)\n",
        "  def forward(self,z):\n",
        "    gsa_output = self.gsaunit(z)\n",
        "    added = gsa_output+z\n",
        "    output = self.batchnorm1(added)\n",
        "    # output = self.ffn1(normalized)\n",
        "    # output = F.relu(output)\n",
        "    output = self.dropout(output)\n",
        "    # output = self.ffn2(output)\n",
        "    # added = normalized+output\n",
        "    # normalized = self.batchnorm2(added)\n",
        "    return output \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdFT0If9lcr"
      },
      "source": [
        "class Categorize(nn.Module):\n",
        "  def __init__(self,d,num_features = 32+49,c_d = 64):\n",
        "    super(Categorize,self).__init__()\n",
        "    # self.fc1 = nn.Linear(num_features*d,8*c_d)\n",
        "    # self.fc2 = nn.Linear(8*c_d,4*c_d)\n",
        "    # self.fc3 = nn.Linear(4*c_d,c_d)\n",
        "    # self.LSTM = nn.LSTM(d,2*c_d,batch_first = True,bidirectional=True)\n",
        "    # self.fc4 = nn.Linear(c_d,1)\n",
        "    self.fc = nn.Linear(2*32,1)\n",
        "    self.conv2 = nn.Conv1d(num_features,32,3,padding = 1)\n",
        "    self.conv3 = nn.Conv1d(num_features,32,5,padding = 2)\n",
        "    self.maxpooling = nn.MaxPool1d(d)\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    # x = x.view(x.size(0),-1)\n",
        "    # _,(output,cell) = self.LSTM(x)\n",
        "    # output = torch.cat((output[0],output[1]),1)\n",
        "    # output = self.dropout(x)\n",
        "    # output = self.fc1(x)\n",
        "    # output = F.relu(output)\n",
        "    # output = self.fc2(output)\n",
        "    # output = F.relu(output)\n",
        "    # output = self.dropout(output)\n",
        "    # output = self.fc3(output)\n",
        "    # output = F.relu(output)\n",
        "    # output = self.fc4(output)\n",
        "    # output = torch.sigmoid(output)\n",
        "    output2 = self.conv2(x)\n",
        "    output2 = F.relu(output2)\n",
        "    output3 = self.conv3(x)\n",
        "    output3 = F.relu(output3)\n",
        "    output = torch.cat((output2,output3),1)\n",
        "    output = self.maxpooling(output)\n",
        "    output = output.squeeze(2)\n",
        "    output = self.fc(output)\n",
        "    output = torch.sigmoid(output)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MvXUj3eu2A1"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,d,d_g,output_channels,num_features,c_d,mlp_size = 64,d_x = 128,d_y = 512,text_dropout = 0.1,L=1):\n",
        "    super(Model,self).__init__()\n",
        "    self.text_model = textModel(mlp_size, d_x,text_dropout)\n",
        "    self.image_model = imageModel(output_channels)\n",
        "    self.fcx = nn.Linear(d_x,d)\n",
        "    self.fcy = nn.Linear(d_y,d)\n",
        "    self.L = L\n",
        "    self.batchnorm1 = nn.BatchNorm1d(32)\n",
        "    self.batchnorm2 = nn.BatchNorm1d(output_channels)\n",
        "    self.UA_model1 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model2 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model3 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model4 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model5 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model6 = UA(d,d_g,num_features).to(device)\n",
        "    # self.UA_model7 = UA(d,d_g,num_features).to(device)\n",
        "    self.categorize = Categorize(d,num_features,c_d)\n",
        "  \n",
        "  def forward(self,text,image):\n",
        "    text_output = self.text_model(text)\n",
        "    image = self.image_model(image)\n",
        "    # text_output = self.fcx(text_output)\n",
        "    image_output = self.fcy(image)\n",
        "    text_output = self.batchnorm1(text_output)\n",
        "    image_output = self.batchnorm2(image_output)\n",
        "    z = torch.cat((text_output,image_output),1).to(device)\n",
        "    z = self.UA_model1(z)\n",
        "    # z = self.UA_model2(z)\n",
        "    # z = self.UA_model3(z)\n",
        "    # z = self.UA_model4(z)\n",
        "    # z = self.UA_model5(z)\n",
        "    # z = self.UA_model6(z)\n",
        "    # z = self.UA_model7(z)\n",
        "    output = self.categorize(z)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO4xad8MVTja"
      },
      "source": [
        "output_channels = 100\n",
        "num_features = 32+output_channels\n",
        "model = Model(d = 64,d_g = 32,output_channels=output_channels,num_features = num_features,c_d = 16,L=2,d_y = 49).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ41x4jhscaY"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PovXBuxgOSmG"
      },
      "source": [
        "# Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2xhr5gHOxl"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDf9AxgJWpHX"
      },
      "source": [
        "#Training Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNffU1fkOWlg"
      },
      "source": [
        "##Training and Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3E_ESTIWoG-"
      },
      "source": [
        "def train(model,dataset,epochs,batch_size=10,criterion = nn.BCELoss(),optimizer = \"Adam\"):\n",
        "  criterion = nn.BCELoss()\n",
        "  if optimizer == \"Adam\":\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "  elif optimizer == \"SGD\":\n",
        "    optimizer = optim.SGD(model.parameters(),lr = 0.001)\n",
        "  elif optimizer == \"AdaDelta\":\n",
        "    optimizer = optim.Adadelta(model.parameters())\n",
        "  else:\n",
        "    print(\"Choose from Adam,SGD,AdaDelta\")\n",
        "    return\n",
        "  train_dl = DataLoader(dataset,batch_size = batch_size,shuffle = True)\n",
        "  length = len(train_dl)\n",
        "  data_length = dataset.__len__()\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    print(\"Epoch: {}\".format(epoch+1))\n",
        "    for i, data in enumerate(train_dl):\n",
        "      progress_batch(i,length)\n",
        "      x,image,label = data[0].to(device),data[1].to(device),data[2].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(x,image)\n",
        "      loss = criterion(outputs,label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss+=loss.item()\n",
        "    running_loss/=data_length\n",
        "    print(\"   Loss:\",f' {running_loss:.5f}')\n",
        "  print(\"Finished Training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpZ6uAwJBjy"
      },
      "source": [
        "def evaluate(model,dataset,criterion = nn.BCELoss()):\n",
        "  correct = 0\n",
        "  total = dataset.__len__()\n",
        "  BATCH_SIZE = 1000\n",
        "  total_loss = 0\n",
        "  val_dl = DataLoader(dataset,batch_size = BATCH_SIZE)\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      x,image,label = data[0].to(device),data[1].to(device),data[2].to(device)\n",
        "      outputs = model(x,image)\n",
        "      loss = criterion(outputs,label)\n",
        "      outputs = outputs.detach()\n",
        "      outputs = outputs.squeeze(1)\n",
        "      label = label.squeeze(1)\n",
        "      predicted = (outputs>0.5).float()\n",
        "      result = torch.sum(predicted==label)\n",
        "      correct+=result.item()\n",
        "      total_loss+=loss.item()\n",
        "  total_loss/=total\n",
        "  accuracy = correct/total\n",
        "  print(\"Accuracy: {} || Loss: {:.5f}\".format(accuracy,total_loss))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtY3QCIfZgts"
      },
      "source": [
        "##Saving and Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udp9yO6tKs5t"
      },
      "source": [
        "from datetime import datetime\n",
        "def save(model,name = None):\n",
        "  now = datetime.now()\n",
        "  dt_string = now.strftime(\"%d-%m-%Y:%H:%M:%S\")\n",
        "  PATH = \"/content/drive/My Drive/Facebook Hateful Memes/Model/\"\n",
        "  if name is not None:\n",
        "    PATH+=name\n",
        "  else:\n",
        "    PATH+=dt_string\n",
        "  PATH+=\".pth\"\n",
        "  torch.save(model, PATH)\n",
        "  print(\"Successfully Saved at\",PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKNlcsDQVPz_"
      },
      "source": [
        "##Using Cross Validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy0AUqf5VO4l"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits=10)\n",
        "train_text_tensor = get_text_tensor(train_data,tokenizer)\n",
        "train_image_tensor = get_image_tensor(PATH_train,for_conv = True)\n",
        "train_label_tensor = torch.Tensor(train_data['label']).view(train_image_tensor.size(0),1)\n",
        "dev_text_tensor = get_text_tensor(dev_data,tokenizer)\n",
        "dev_image_tensor = get_image_tensor(PATH_dev, for_conv=True)\n",
        "dev_label_tensor = torch.Tensor(dev_data['label']).view(dev_image_tensor.size(0),1)\n",
        "text_tensor = torch.cat((train_text_tensor,dev_text_tensor),0)\n",
        "image_tensor = torch.cat((train_image_tensor,dev_image_tensor),0)\n",
        "label_tensor = torch.cat((train_label_tensor,dev_label_tensor),0)\n",
        "print(\"Text Tensor:\",text_tensor.shape)\n",
        "print(\"IMage Tensor:\",image_tensor.shape)\n",
        "print(\"Label Tensor:\",label_tensor.shape)\n",
        "print(\"Start Training:\")\n",
        "for fold, (train_index, test_index) in enumerate(kfold.split(train_text_tensor)):\n",
        "  print(\"Fold #:\",fold+1)\n",
        "  text_train_fold = train_text_tensor[train_index]\n",
        "  image_train_fold = train_image_tensor[train_index]\n",
        "  label_train_fold = train_label_tensor[train_index]\n",
        "  text_test_fold = text_tensor[test_index]\n",
        "  image_test_fold = image_tensor[test_index]\n",
        "  label_test_fold = label_tensor[test_index]\n",
        "  train_fold_dataset = torch.utils.data.TensorDataset(text_train_fold,image_train_fold,label_train_fold)\n",
        "  test_fold_dataset = torch.utils.data.TensorDataset(text_test_fold,image_test_fold,label_test_fold)\n",
        "  train(model,train_fold_dataset,5,batch_size=100,criterion = nn.BCELoss(),optimizer = \"Adam\")\n",
        "  evaluate(model,test_fold_dataset)\n",
        "  print(\"Validation Accuracy:\")\n",
        "  evaluate(model,dev_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he14csPbggKi"
      },
      "source": [
        "print(\"Training Accuracy:\")\n",
        "evaluate(model,train_dataset)\n",
        "print(\"Validation Accuracy:\")\n",
        "evaluate(model,dev_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15FXLT0gKnxY"
      },
      "source": [
        "save(model,\"withpreembed100reg-512x49-acc0.953valacc0.514\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wIb6FyTJPnF"
      },
      "source": [
        "model_check = torch.load(\"/content/drive/My Drive/Facebook Hateful Memes/Model/512x49-acc0.99valacc0.516.pth\")\n",
        "evaluate(model_check,train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18vZv9hGdUOO"
      },
      "source": [
        "##Testing Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPWQK_Oroivq"
      },
      "source": [
        "text_tensor = get_text_tensor(test_data)\n",
        "ids = test_data['id']\n",
        "print(\"Text Tensor:\",type(text_tensor),text_tensor.shape)\n",
        "image_tensor = get_image_tensor(PATH_test,alternate =True)\n",
        "print(image_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wURN9N_6dZzR"
      },
      "source": [
        "with torch.no_grad():\n",
        "  x = text_tensor.to(device)\n",
        "  image = image_tensor.to(device)\n",
        "  outputs = model(x,image)\n",
        "  outputs = outputs.detach()\n",
        "  output = outputs.squeeze(1)\n",
        "  predicted = (output>0.5).int()\n",
        "final_output = np.array(output.cpu())\n",
        "final_predicted = np.array(predicted.cpu())\n",
        "print(ids.shape,final_output.shape,final_predicted.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEPdXAEsqqVE"
      },
      "source": [
        "data = {'id':list(ids),'proba':list(final_output),'label':list(final_predicted)}\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9fAC5MPrMbt"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojHwgz9-xHtz"
      },
      "source": [
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y:%H:%M:%S\")\n",
        "name = \"withpreembed100reg-512x49-acc0.953valacc0.514\"\n",
        "PATH = \"/content/drive/My Drive/Facebook Hateful Memes/SubmissionFile/\"+name+\".csv\"\n",
        "df.to_csv(PATH,index=False)\n",
        "print(\"saved successfully at\",PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZxRB560loVF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}