{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facebook_Hateful_Memes [Model 1].ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ST-EtQ6B2OrSj10HvQ7FAUL2EuCw5L_m",
      "authorship_tag": "ABX9TyPN0scz6XV9ainGLapRI/VF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashaditya369/mutlimodal-models/blob/main/Facebook_Hateful_Memes_%5BModel_1%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjGA4i9q5WVa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import skimage.transform\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "from PIL import Image\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtext.data import Field\n",
        "from torch.autograd import Variable\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "# device = \"cpu\"\n",
        "\n",
        "print(\"Using device : \", device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7A-61zZ6HWE"
      },
      "source": [
        "train_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/train.jsonl\",lines = True)\n",
        "dev_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/dev.jsonl\",lines = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-FIv75d9WPK"
      },
      "source": [
        "train_data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgfdM_QYa-o2"
      },
      "source": [
        "def progress_batch(i,Len, width=30):\n",
        "  left = int(width * (i+1)*100/Len) // 100\n",
        "  right = width - left\n",
        "  print('\\r[', '*' * left, ' ' * right, ']',f'{str(i+1)}/{str(Len)}',\n",
        "        sep='', end='', flush=True)\n",
        "def progress(percent=0, width=30):\n",
        "  left = int(width * percent) // 100\n",
        "  right = width - left\n",
        "  print('\\r[', '#' * left, ' ' * right, ']',\n",
        "        f' {percent:.2f}%',\n",
        "        sep='', end='', flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF0bGrmbo-hS"
      },
      "source": [
        "#Text Preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oluPo7o7wCJ6"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8yerY4jY0SA"
      },
      "source": [
        "##Fit one Training Data Texts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fKIU9ZNpCl0"
      },
      "source": [
        "texts = train_data['text']\n",
        "sentences = list(texts)\n",
        "tokenizer  = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(\"Vocab Size: \",len(word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fygd5Ssz2TyC"
      },
      "source": [
        "#Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHGJGk6u2XCA"
      },
      "source": [
        "class TextImageLabels(Dataset):\n",
        "  def __init__(self,text_tensor,image_tensor,label_tensor):\n",
        "    self.text = text_tensor\n",
        "    self.image = image_tensor\n",
        "    self.labels = label_tensor\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (self.text[idx],self.image[idx],self.labels[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d19oMq-e37dJ"
      },
      "source": [
        "def get_dataset(PATH,data,tokenizer):\n",
        "  texts = data['text']\n",
        "  sentences = list(texts)\n",
        "  word_index = tokenizer.word_index\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "  padded = pad_sequences(sequences,maxlen = 30)\n",
        "  text_tensor = to_tensor(padded)[0].long()\n",
        "  print(\"Text Tensor:\",type(text_tensor),text_tensor.shape)\n",
        "  image = np.load(PATH,allow_pickle=True)\n",
        "  image = image.reshape(image.shape[0],-1)\n",
        "  image_tensor = to_tensor(image).squeeze(0)\n",
        "  print(\"Image Tensor:\",type(image_tensor),image_tensor.shape)\n",
        "  label_tensor = torch.Tensor(data['label']).view(image_tensor.size(0),1)\n",
        "  print(\"Label Tensor:\", type(label_tensor),label_tensor.shape)\n",
        "  dataset = TextImageLabels(text_tensor,image_tensor,label_tensor)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LFyAF4BY_op"
      },
      "source": [
        "PATH = \"/content/drive/My Drive/Facebook Hateful Memes/train_channel_features.npy\"\n",
        "train_dataset = get_dataset(PATH,train_data,tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_Zd0fnp0qrx"
      },
      "source": [
        "#Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIrIM4IKGJ0A"
      },
      "source": [
        "VOCAB_SIZE = len(word_index)+1\n",
        "HIDDEN_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2JYguNV6gsZ"
      },
      "source": [
        "class PreLSTM(nn.Module):\n",
        "  def __init__(self,vocab_size,hidden_size = 64,LSTM_layers=2,dropout = 0.3):\n",
        "    super(PreLSTM,self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.LSTM_layers = LSTM_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embed = nn.Embedding(vocab_size, hidden_size)\n",
        "    self.biLSTM = nn.LSTM(hidden_size,hidden_size,dropout=(0 if LSTM_layers == 1 else dropout),num_layers = LSTM_layers,bidirectional = True)\n",
        "  def forward(self,x,hidden = None):\n",
        "    x= x.T\n",
        "    embedded = self.embed(x)\n",
        "    output,hidden = self.biLSTM(embedded)\n",
        "    return output,hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgdFT0If9lcr"
      },
      "source": [
        "class Attn(torch.nn.Module):\n",
        "    def __init__(self,hidden_size=2*64):\n",
        "        super(Attn, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
        "        self.final = torch.nn.Linear(self.hidden_size,1)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        repeator = hidden.expand(encoder_outputs.size(0),-1,-1)\n",
        "        concat = torch.cat((repeator, encoder_outputs), -1)\n",
        "        e = self.attn(concat)\n",
        "        e = torch.tanh(e)\n",
        "        e = self.final(e)\n",
        "        alphas = F.relu(e)\n",
        "        context = encoder_outputs*alphas\n",
        "        context = torch.sum(context,dim = 0)\n",
        "        return context"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MvXUj3eu2A1"
      },
      "source": [
        "class PostLSTM(nn.Module):\n",
        "    def __init__(self,hidden_size=2*64, output_size=50, n_layers=1, dropout=0.1):\n",
        "        super(PostLSTM, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.lstm = nn.LSTMCell(hidden_size, hidden_size)\n",
        "        self.attn = Attn(hidden_size).to(device)\n",
        "\n",
        "    def forward(self,last_hidden, encoder_outputs):\n",
        "        hidden,cellState = last_hidden\n",
        "        output = torch.empty(self.output_size,encoder_outputs.shape[1],encoder_outputs.shape[2],device = device)\n",
        "        for i in range(self.output_size):\n",
        "          context = self.attn(hidden, encoder_outputs)\n",
        "          hidden,cellState = self.lstm(context,(hidden,cellState))\n",
        "          output[i,:,:] = F.relu(hidden)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-76hQ06FMKOg"
      },
      "source": [
        "class Concatenate(nn.Module):\n",
        "    def __init__(self,hidden_size=2*64, output_size=50, n_layers=2, dropout=0.01,dropout_fc = 0.2):\n",
        "        super(Concatenate, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.final = torch.nn.Linear(self.hidden_size,1)\n",
        "        self.image_layer = torch.nn.Linear(25088,4096)\n",
        "        self.image_layer1 = torch.nn.Linear(4096,4096)\n",
        "        self.image_layer2 = torch.nn.Linear(4096,1000)\n",
        "        self.image_layer3 = nn.Linear(1000,output_size)\n",
        "        self.final_one = torch.nn.Linear(4*(50+output_size),128)\n",
        "        self.final_one2 = torch.nn.Linear(128,64)\n",
        "        self.drop = nn.Dropout(p =dropout_fc)\n",
        "        self.choose = torch.nn.Linear(64,1)\n",
        "        self.biLSTM = nn.LSTM(1,2,dropout=(0 if n_layers == 1 else dropout),num_layers = n_layers,bidirectional = True)\n",
        "    def forward(self,x,image):\n",
        "        result = self.final(x)\n",
        "        result_text = F.relu(result).view(result.shape[0],result.shape[1])\n",
        "        result = self.image_layer(image)\n",
        "        result = F.relu(result).to(device)\n",
        "        result = self.image_layer1(result)\n",
        "        result = F.relu(result)\n",
        "        result = self.image_layer2(result)\n",
        "        result = F.relu(result)\n",
        "        result = self.image_layer3(result)\n",
        "        result_image = F.relu(result)\n",
        "        result_image = result_image.t()\n",
        "        final = torch.cat((result_text,result_image),0)\n",
        "        final = final.view(final.shape[0],final.shape[1],1)\n",
        "        output,hidden = self.biLSTM(final)\n",
        "        output = torch.cat((output[:,:,0],output[:,:,1],output[:,:,2],output[:,:,3]),0).t()\n",
        "        output = self.final_one(output)\n",
        "        output = F.relu(output)\n",
        "        output = self.drop(output)\n",
        "        output = self.final_one2(output)\n",
        "        output = F.relu(output)\n",
        "        output = self.choose(output)\n",
        "        output = torch.sigmoid(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0A5DaiGtp9O"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self,vocab_size,hidden_size = 64,pre_n_layers=2,pre_dropout = 0,post_output_size = 50,post_n_layers = 1,post_dropout = 0,pic_output_size = 50,con_n_layers = 1,con_dropout = 0,dropout_fc=0):\n",
        "    super(Model, self).__init__()\n",
        "    self.idx = 0  #It can be 0 or 2\n",
        "    self.preLSTM = PreLSTM(vocab_size,hidden_size,pre_n_layers,pre_dropout).to(device)\n",
        "    self.postLSTM = PostLSTM(2*hidden_size,post_output_size, post_n_layers, post_dropout).to(device)\n",
        "    self.concatenationModel = Concatenate(2*hidden_size, pic_output_size, con_n_layers, con_dropout,dropout_fc).to(device)\n",
        "  def forward(self,x,image):\n",
        "    encoder_out,encoder_hidden = self.preLSTM(x)\n",
        "    final_hidden = torch.cat((encoder_hidden[0][self.idx],encoder_hidden[0][self.idx+1]),1)\n",
        "    final_cell = torch.cat((encoder_hidden[1][self.idx],encoder_hidden[1][self.idx+1]),1)\n",
        "    last_hidden = (final_hidden,final_cell)\n",
        "    post_output = self.postLSTM(last_hidden,encoder_out)\n",
        "    output = self.concatenationModel(post_output,image)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U52hfOwnZv86"
      },
      "source": [
        "##Creating Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ41x4jhscaY"
      },
      "source": [
        "model = Model(VOCAB_SIZE,HIDDEN_SIZE,pre_n_layers=1,pre_dropout = 0,post_output_size = 50,post_dropout = 0,pic_output_size = 64,con_n_layers = 2,con_dropout = 0.01,dropout_fc=0.2)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PovXBuxgOSmG"
      },
      "source": [
        "# Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2xhr5gHOxl"
      },
      "source": [
        "import torch.optim as optim\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adadelta(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDf9AxgJWpHX"
      },
      "source": [
        "#Training Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNffU1fkOWlg"
      },
      "source": [
        "##Training and Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3E_ESTIWoG-"
      },
      "source": [
        "def train(model,dataset,epochs,batch_size=10):\n",
        "  train_dl = DataLoader(dataset,batch_size = batch_size,shuffle = True)\n",
        "  length = len(train_dl)\n",
        "  data_length = dataset.__len__()\n",
        "  for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    print(\"Epoch: {}\".format(epoch+1))\n",
        "    for i, data in enumerate(train_dl):\n",
        "      progress_batch(i,length)\n",
        "      x,image,label = data[0].to(device),data[1].to(device),data[2].to(device)\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(x,image)\n",
        "      loss = criterion(outputs,label)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss+=loss.item()\n",
        "    running_loss/=data_length\n",
        "    print(\"   Loss:\",f' {running_loss:.5f}')\n",
        "  print(\"Finished Training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpZ6uAwJBjy"
      },
      "source": [
        "def evaluate(model,dataset):\n",
        "  correct = 0\n",
        "  total = dataset.__len__()\n",
        "  BATCH_SIZE = 10\n",
        "  total_loss = 0\n",
        "  val_dl = DataLoader(dataset,batch_size = BATCH_SIZE)\n",
        "  with torch.no_grad():\n",
        "    for data in val_dl:\n",
        "      x,image,label = data[0].to(device),data[1].to(device),data[2].to(device)\n",
        "      outputs = model(x,image)\n",
        "      loss = criterion(outputs,label)\n",
        "      outputs = outputs.detach()\n",
        "      outputs = outputs.squeeze(1)\n",
        "      label = label.squeeze(1)\n",
        "      predicted = (outputs>0.5).float()\n",
        "      result = torch.sum(predicted==label)\n",
        "      correct+=result.item()\n",
        "      total_loss+=loss.item()\n",
        "  total_loss/=total\n",
        "  accuracy = correct/total\n",
        "  print(\"Accuracy: {} || Loss: {:.5f}\".format(accuracy,total_loss))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtY3QCIfZgts"
      },
      "source": [
        "##Saving and Loading Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udp9yO6tKs5t"
      },
      "source": [
        "from datetime import datetime\n",
        "def save(model):\n",
        "  now = datetime.now()\n",
        "  dt_string = now.strftime(\"%d-%m-%Y:%H:%M:%S\")\n",
        "  PATH = \"/content/drive/My Drive/Facebook Hateful Memes/Model/\"+dt_string\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "  print(\"Successfully Saved at\",PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxtAcF5fXAHF"
      },
      "source": [
        "def load(PATH =None):\n",
        "  model = Model(VOCAB_SIZE,HIDDEN_SIZE)\n",
        "  model.to(device)\n",
        "  if PATH is None:\n",
        "    PATH = \"/content/drive/My Drive/Facebook Hateful Memes/Model/20-08-2020:13:41:38\"  #Change this to original file.\n",
        "  model.load_state_dict(torch.load(PATH))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN0u5Sqp9ce-"
      },
      "source": [
        "train(model,train_dataset,7,batch_size=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF_bnphYsx39"
      },
      "source": [
        "save(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7G6SZdYfK60"
      },
      "source": [
        "dev_dataset = get_dataset(\"/content/drive/My Drive/Facebook Hateful Memes/dev_channel_features.npy\",dev_data,tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he14csPbggKi"
      },
      "source": [
        "print(\"Training Accuracy:\")\n",
        "evaluate(model,train_dataset)\n",
        "print(\"Validation Accuracy:\")\n",
        "evaluate(model,dev_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18vZv9hGdUOO"
      },
      "source": [
        "##Testing Part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPWQK_Oroivq"
      },
      "source": [
        "test_data = pd.read_json(\"/content/drive/My Drive/Facebook Hateful Memes/test.jsonl\",lines = True)\n",
        "print(test_data['id'].shape)\n",
        "test_PATH = \"/content/drive/My Drive/Facebook Hateful Memes/test_channel_features.npy\"\n",
        "print(test_data.shape[0])\n",
        "ids = test_data['id']\n",
        "texts = test_data['text']\n",
        "sentences = list(texts)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences,maxlen = 30)\n",
        "text_tensor = to_tensor(padded)[0].long()\n",
        "print(\"Text Tensor:\",type(text_tensor),text_tensor.shape)\n",
        "image = np.load(test_PATH,allow_pickle=True)\n",
        "image = image.reshape(image.shape[0],-1)\n",
        "image_tensor = to_tensor(image).squeeze(0)\n",
        "print(image_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wURN9N_6dZzR"
      },
      "source": [
        "with torch.no_grad():\n",
        "  x = text_tensor.to(device)\n",
        "  image = image_tensor.to(device)\n",
        "  outputs = model(x,image)\n",
        "  outputs = outputs.detach()\n",
        "  outputs = outputs.squeeze(1)\n",
        "  predicted = (outputs>0.5).int()\n",
        "final_output = np.array(outputs.cpu())\n",
        "final_predicted = np.array(predicted.cpu())\n",
        "print(ids.shape,final_output.shape,final_predicted.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEPdXAEsqqVE"
      },
      "source": [
        "data = {'id':list(ids),'proba':list(final_output),'label':list(final_predicted)}\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9fAC5MPrMbt"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojHwgz9-xHtz"
      },
      "source": [
        "now = datetime.now()\n",
        "dt_string = now.strftime(\"%d-%m-%Y:%H:%M:%S\")\n",
        "PATH = \"/content/drive/My Drive/Facebook Hateful Memes/SubmissionFile/\"+dt_string+\".csv\"\n",
        "df.to_csv(PATH,index=False)\n",
        "print(\"Saved CSV File at\",PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMOE5mXk_Uuy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}